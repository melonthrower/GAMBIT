import json
import argparse
from collections import defaultdict
import os

def analyze_evaluation_results(result_file_path: str):

    if not os.path.exists(result_file_path):
        print(f"Error: The file '{result_file_path}' was not found.")
        print("Please ensure you have run the evaluation script and provided the correct path.")
        return

    try:
        with open(result_file_path, 'r', encoding='utf-8') as f:
            results_data = json.load(f)
    except json.JSONDecodeError:
        print(f"Error: Could not decode JSON from '{result_file_path}'. The file might be corrupted or empty.")
        return

    action_stats = defaultdict(lambda: {"count": 0, "tm_count": 0, "em_count": 0})

    for step_result in results_data:
        eval_info = step_result.get("eval_result")
        if not eval_info:
            continue

        ground_truth_action = eval_info.get("answer", {}).get("action_type")
        if not ground_truth_action:
            continue
        
        action_type = ground_truth_action.upper()

        action_stats[action_type]["count"] += 1
        if eval_info.get("type_match", False):
            action_stats[action_type]["tm_count"] += 1
        if eval_info.get("exact_match", False):
            action_stats[action_type]["em_count"] += 1

    if not action_stats:
        print("No evaluation data could be processed from the file.")
        return

    print("\n" + "="*65)
    print(" " * 18 + "Action Performance Summary")
    print("="*65)
    print(f"{'Action Type':<20} | {'Count':>10} | {'Type Match (%)':>15} | {'Exact Match (%)':>15}")
    print("-"*65)

    total_count = 0
    total_tm_count = 0
    total_em_count = 0

    for action_type in sorted(action_stats.keys()):
        stats = action_stats[action_type]
        count = stats["count"]
        tm_count = stats["tm_count"]
        em_count = stats["em_count"]

        # Calculate percentages, handling division by zero
        tm_percent = (tm_count / count * 100) if count > 0 else 0
        em_percent = (em_count / count * 100) if count > 0 else 0

        # Update totals
        total_count += count
        total_tm_count += tm_count
        total_em_count += em_count
        
        print(f"{action_type:<20} | {count:>10} | {tm_percent:>14.2f} | {em_percent:>14.2f}")

    print("-"*65)
    total_tm_percent = (total_tm_count / total_count * 100) if total_count > 0 else 0
    total_em_percent = (total_em_count / total_count * 100) if total_count > 0 else 0
    print(f"{'Overall Total':<20} | {total_count:>10} | {total_tm_percent:>14.2f} | {total_em_percent:>14.2f}")
    print("="*65 + "\n")


if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="Calculate Type Match (TM) and Exact Match (EM) statistics per action type from an evaluation result file.",
        formatter_class=argparse.RawTextHelpFormatter
    )
    parser.add_argument(
        "--input",
        type=str,
        default=True,
        help="Path to the 'result.json' file generated by the run_eval_agent.py script."
    )
    args = parser.parse_args()
    
    analyze_evaluation_results(args.input)